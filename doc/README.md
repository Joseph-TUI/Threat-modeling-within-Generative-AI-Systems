<p align="center">
	<a href="https://github.com/Joseph-TUI/Threat-modeling-within-Generative-AI-Systems/blob/main/README.md">
		<img align="center" alt="Threat modeling-Security Practices" src="/Pic/main.JPG" height="170">
	</a>
</p>

# STRIDE Approach towards Generative AI

In the procedure, the following standard STRIDE-based questions must be taken into account. Risk must be calculated based on the data, and risks must then be ranked. 
[This page](https://github.com/Joseph-TUI/Threat-modeling-within-Generative-AI-Systems/blob/main/tecdoc/README.md#risk-assessment-in-ai-systems) explains the risk calculation and associated ranking.


| STRIDE	| Adversarial Attack | Model Poisoning | Output Manipulation |
|---	|---	|---	|---	|
|[Spoofing]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Tampering: | What safeguards can be implemented to detect and mitigate attempts to manipulate the training data with adversarial inputs? How to ensure the integrity of the Generative AI model during the training process to resist tampering attempts?.|What safeguards are in place to detect and prevent unauthorized alterations to the training dataset? How to ensure the integrity of the training data throughout the model training process.| What safeguards can be implemented to detect and prevent unauthorized alterations to the generated output,protecting against manipulation that compromises privacy? How can we ensure the integrity of the generated output and prevent tampering with sensitive information?.|
|[Repudiation]| How to establish accountability for any alterations introduced by adversarial attacks?.|Are there mechanisms to track and trace changes made to the training data,preventing repudiation of unauthorized modifications? How we establish accountability for any alterations to the training dataset?.| Are there mechanisms in place to trace and verify the source of generated output, preventing the denial of unauthorized modifications? How can we establish accountability for any alterations introduced to the output that may violate privacy?.|
|[Information Disclosure]| How to safeguard against inadvertent disclosure of proprietary information or vulnerabilities during the model training?.|How can we prevent unintended disclosure of proprietary or confidential information during the model training?.| Measures can be employed to restrict the disclosure of sensitive information within the generated output?. How can we safeguard against inadvertent disclosure of private or confidential details during the generation process?.|
|[Denial of Service]| What strategies can be employed to ensure the continuity of the training process in the face of potential denial-of-service attacks?.|What measures can be implemented to ensure the continuity of the training process despite potential denial-of-service attacks?.| How resilient is the Generative AI model against attempts to disrupt the generation process and deny service? What strategies can be employed to ensure the continuity of the output generation process in the face of potential denial-of-service attacks?.|
|[Elevation of Privilege]| Are there controls in place to thwart adversarial attempts to manipulate the model and escalate privileges? .|Are there controls in place to prevent unauthorized access that could lead to an elevation of privileges during the training process?.| Are there controls in place to thwart attempts to manipulate the model output and escalate privileges in a way that compromises privacy?.|