<p align="center">
	<a href="https://github.com/Joseph-TUI/Threat-modeling-within-Generative-AI-Systems/blob/main/README.md">
		<img align="center" alt="Threat modeling-Security Practices" src="/Pic/main.JPG" height="170">
	</a>
</p>

# STRIDE Approach towards Generative AI

We have designed a Threat Modeling template specifically tailored for Generative AI Systems. Developers and architects can readily apply this template to their application structures. The repository is established in accordance with the research paper titled "Developing a practical approach to threat modeling within Generative AI Systems," present at the International Conference on Advanced Computing, Communication, and Electrical Systems (ICACCES) in 2024.	 


| STRIDE	| Adversarial Attack | Model Poisoning | Output Manipulation |
|---	|---	|---	|---	|
|[Spoofing]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Tampering: | What safeguards can be implemented to detect and mitigate attempts to manipulate the training data with adversarial inputs? How to ensure the integrity of the Generative AI model during the training process to resist tampering attempts?.|What safeguards are in place to detect and prevent unauthorized alterations to the training dataset? How to ensure the integrity of the training data throughout the model training process.| What safeguards can be implemented to detect and prevent unauthorized alterations to the generated output,protecting against manipulation that compromises privacy? How can we ensure the integrity of the generated output and prevent tampering with sensitive information?.|
|[Repudiation]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Information Disclosure]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Denial of Service]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Elevation of Privilege]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|