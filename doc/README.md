<p align="center">
	<a href="https://github.com/Joseph-TUI/Threat-modeling-within-Generative-AI-Systems/blob/main/README.md">
		<img align="center" alt="Threat modeling-Security Practices" src="/Pic/main.JPG" height="170">
	</a>
</p>

# STRIDE Approach towards Generative AI

We have designed a Threat Modeling template specifically tailored for Generative AI Systems. Developers and architects can readily apply this template to their application structures. The repository is established in accordance with the research paper titled "Developing a practical approach to threat modeling within Generative AI Systems," present at the International Conference on Advanced Computing, Communication, and Electrical Systems (ICACCES) in 2024.	 


| STRIDE	| Adversarial Attack | Model Poisoning | Output Manipulation |
|---	|---	|---	|---	|
|[Spoofing]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Spoofing]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|
|[Spoofing]| How to enhance the authentication mechanisms to prevent the introduction of adversarial inputs posing as legitimate data during the training phase? Are there measures in place to verify the authenticity of the training data and ensure it is not manipulated by malicious entities?.|How to ensure the authenticity of the training data sources to prevent malicious spoofing attempts? Are there measures in place to verify and authenticate the origin of the training data?.| How to authenticate and ensure the legitimacy of the output generated by the Generative AI model to prevent spoofing attempts? Are there measures in place to detect and counteract outputs that impersonate legitimate information?.|